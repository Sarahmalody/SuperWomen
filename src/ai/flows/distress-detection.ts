// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A distress detection AI agent.
 *
 * - detectDistress - A function that handles the distress detection process.
 * - DetectDistressInput - The input type for the detectDistress function.
 * - DetectDistressOutput - The return type for the detectDistress function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const DetectDistressInputSchema = z.object({
  audioDataUri: z
    .string()
    .describe(
      "An audio recording of the user's voice, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
  transcript: z.string().describe('The transcript of the user utterance.'),
});
export type DetectDistressInput = z.infer<typeof DetectDistressInputSchema>;

const DetectDistressOutputSchema = z.object({
  isDistressed: z
    .boolean()
    .describe(
      'Whether or not the user is distressed, based on emotion and tone analysis.'
    ),
  confidence: z
    .number()
    .describe(
      'A number between 0 and 1 indicating the confidence in the distress detection.'
    ),
  reason: z
    .string()
    .describe('The reasoning behind the distress detection result.'),
});
export type DetectDistressOutput = z.infer<typeof DetectDistressOutputSchema>;

export async function detectDistress(input: DetectDistressInput): Promise<DetectDistressOutput> {
  return detectDistressFlow(input);
}

const prompt = ai.definePrompt({
  name: 'detectDistressPrompt',
  input: {schema: DetectDistressInputSchema},
  output: {schema: DetectDistressOutputSchema},
  prompt: `You are an AI expert in detecting distress in human voices. Analyze the provided audio transcript and the user's tone and emotion to determine if the user is distressed.

Consider the following factors:
- Use the audio data to analyze tone and emotion.
- The content of the transcript.
- The presence of keywords associated with distress.

Return a boolean value indicating whether the user is distressed, a confidence score between 0 and 1, and a reason for your determination.

Here is the audio data: {{media url=audioDataUri}}
Here is the transcript: {{{transcript}}}`,
});

const detectDistressFlow = ai.defineFlow(
  {
    name: 'detectDistressFlow',
    inputSchema: DetectDistressInputSchema,
    outputSchema: DetectDistressOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);
